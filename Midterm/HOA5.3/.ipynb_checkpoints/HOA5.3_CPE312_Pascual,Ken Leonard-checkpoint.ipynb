{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a47db30-d4b7-4297-a3b7-6ab62ac0358d",
   "metadata": {},
   "source": [
    "[Github](https://github.com/leon-pscl/CPE312_Predictive_Analytics_Using_Machine_Learning/tree/621558b0e773c4ceca8564f39841ed8b4177a9d3/Midterm/HOA5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175241c3-c8ea-43ea-a1a9-89dce8a75c2a",
   "metadata": {},
   "source": [
    "# Activity 5.3: Bagging, Boosting, and Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d492404-3a5e-4bdf-8a9b-f232e7ac2518",
   "metadata": {},
   "source": [
    "Intended Learning Outcomes (ILOs):\n",
    "* Demonstrate the use of bagging technique for classification and regression tasks\n",
    "* Demonstrate boosting and stacking models in solving an identified problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7b8f5-4aa2-41eb-b30d-2e8e2b67bac6",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "* Jupyter Notebook<br>\n",
    "* emails.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff738fa7-d8cd-495b-acd2-1e3c31c8ca39",
   "metadata": {},
   "source": [
    "## Procedure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609fa5a1-cca2-4b77-8078-cc741599f4be",
   "metadata": {},
   "source": [
    "For this activity, you need to perform the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f1b1d-cb74-4315-b0a8-125e343433b4",
   "metadata": {},
   "source": [
    "1. Check the following resources for a review of Bagging and Boosting and Stacking.\n",
    "   * [Bagging_Exercises.ipynb](https://drive.google.com/file/d/1O-xLD-n1lgqMoXL79FHZcO_ePJd3RgDA/view?usp=sharing)\n",
    "   * [Boosting_and_Stacking_Exercises_ANSWERS.ipynb](https://drive.google.com/file/d/1jswsZAkeoWJV8TBM3hdB16tbB-KKlh75/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b3f06-5b56-4cb7-8a94-705a38488a04",
   "metadata": {},
   "source": [
    "2. Using your own dataset, perform bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f90ab9-551c-4df0-9a47-ac255075f8a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Wrangling setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb9392f-12ab-4426-a313-7bffb4b33aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Random Forest and Bagging\n",
    "from sklearn.ensemble import (RandomForestClassifier, BaggingClassifier)\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "#gridsearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e47acec0-795f-4d64-a75f-2b0e421a6e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "email = pd.read_csv('emails.csv')\n",
    "email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20334d2a-7644-41d9-8cbf-004a6bbd1e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints (rows): 5172\n",
      "Number of columns: 3002\n",
      "\n",
      "Data types:\n",
      " Email No.     object\n",
      "the            int64\n",
      "to             int64\n",
      "ect            int64\n",
      "and            int64\n",
      "               ...  \n",
      "military       int64\n",
      "allowing       int64\n",
      "ff             int64\n",
      "dry            int64\n",
      "Prediction     int64\n",
      "Length: 3002, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#read dimensions and dtypes\n",
    "print(\"Number of datapoints (rows):\", email.shape[0])\n",
    "print(\"Number of columns:\", email.shape[1])\n",
    "print(\"\\nData types:\\n\", email.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7015c175-acef-44d6-9c21-5dc5623660a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  valued  \\\n",
       "0    0   0    1    0    0   0    2    0    0   0  ...         0    0       0   \n",
       "1    8  13   24    6    6   2  102    1   27  18  ...         0    0       0   \n",
       "2    0   0    1    0    0   0    8    0    0   4  ...         0    0       0   \n",
       "3    0   5   22    0    5   1   51    2   10   1  ...         0    0       0   \n",
       "4    7   6   17    1    5   2   57    0    9   3  ...         0    0       0   \n",
       "\n",
       "   lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0    0               0         0         0   0    0           0  \n",
       "1    0               0         0         0   1    0           0  \n",
       "2    0               0         0         0   0    0           0  \n",
       "3    0               0         0         0   0    0           0  \n",
       "4    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning\n",
    "#we don't need the email identifier, so remove it\n",
    "no_label_email = email.drop(['Email No.'], axis=1)\n",
    "no_label_email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49e7ef43-9dd7-4c2c-81b8-923f57ce29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      " the           0\n",
      "to            0\n",
      "ect           0\n",
      "and           0\n",
      "for           0\n",
      "             ..\n",
      "military      0\n",
      "allowing      0\n",
      "ff            0\n",
      "dry           0\n",
      "Prediction    0\n",
      "Length: 3001, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(\"\\nMissing values per column:\\n\", no_label_email.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "492e4744-0636-4588-abe0-7cf9fd81ec76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Correlation       p-value\n",
      "160      thanks    -0.271433  4.926148e-88\n",
      "37          hpl    -0.266518  7.952302e-85\n",
      "418       hanks    -0.266070  1.547126e-84\n",
      "785       thank    -0.262384  3.521933e-82\n",
      "99         more     0.258152  1.607936e-79\n",
      "81     attached    -0.236558  1.048551e-66\n",
      "68        daren    -0.236180  1.711801e-66\n",
      "52    forwarded    -0.230765  1.761133e-63\n",
      "42          our     0.228187  4.495713e-62\n",
      "317     subject    -0.227754  7.714997e-62\n",
      "2311         hp    -0.225846  8.229589e-61\n",
      "363        able     0.222219  6.968407e-59\n",
      "290        best     0.221703  1.301847e-58\n",
      "2833         ur     0.220253  7.483086e-58\n",
      "1092        sex     0.220092  9.079039e-58\n",
      "1361        sec     0.217402  2.241652e-56\n",
      "242       money     0.217215  2.799293e-56\n",
      "647        soft     0.213382  2.498362e-54\n",
      "1615         dr     0.212413  7.671000e-54\n",
      "2041         mo     0.210056  1.146765e-52\n"
     ]
    }
   ],
   "source": [
    "#Implement point-biserial correlation to see which columns may have the highest correlation to the prediction\n",
    "from scipy.stats import pointbiserialr\n",
    "import pandas as pd\n",
    "\n",
    "target = 'Prediction'\n",
    "results = []\n",
    "\n",
    "#Loop through predictor columns\n",
    "for col in no_label_email.drop(columns=[target]).select_dtypes(include=np.number).columns:\n",
    "    corr, p_val = pointbiserialr(no_label_email[target], no_label_email[col])\n",
    "    results.append({\"Feature\": col, \"Correlation\": corr, \"AbsCorrelation\": abs(corr), \"p-value\": p_val})\n",
    "\n",
    "#Put into DataFrame and sort\n",
    "results_df = pd.DataFrame(results)\n",
    "top_20 = results_df.sort_values(by=\"AbsCorrelation\", ascending=False).head(20)\n",
    "\n",
    "print(top_20[['Feature', 'Correlation', 'p-value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "936a3195-8203-4fa0-8829-a7ea0ccc4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for modelling\n",
    "X = no_label_email.drop('Prediction', axis=1)\n",
    "y = no_label_email['Prediction']\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99b1a4a1-37a3-470e-9d05-75b5c2e9d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base learners\n",
    "knn_model = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcbe29-ed63-4dd8-8c2d-b8d44341c78b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bagging with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b984911b-345e-47d7-890a-a382265a5049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training & Evaluating Base KNN: 100%|████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base KNN Accuracy: 0.8698453608247423\n",
      "Base KNN ROC-AUC: 0.9333887625592274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#base performance - KNN\n",
    "for _ in tqdm(range(1), desc=\"Training & Evaluating Base KNN\"):\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    knn_pred = knn_model.predict(X_test)\n",
    "    knn_proba = knn_model.predict_proba(X_test)[:, 1]\n",
    "    print(\"Base KNN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
    "    print(\"Base KNN ROC-AUC:\", roc_auc_score(y_test, knn_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29fb06cc-d7cc-4cd0-b968-1e8145880851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bagging with KNN as base: 100%|██████████████████████████████████████████████████████████| 1/1 [00:29<00:00, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging + KNN Accuracy: 0.8646907216494846\n",
      "Bagging + KNN ROC-AUC: 0.9338766065292956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging with KNN as base\n",
    "bagging_knn = BaggingClassifier(\n",
    "    estimator=KNeighborsClassifier(n_neighbors=11),\n",
    "    n_estimators=50,\n",
    "    max_samples=0.7,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "for _ in tqdm(range(1), desc=\"Bagging with KNN as base\"):\n",
    "    bagging_knn.fit(X_train, y_train)\n",
    "    bag_knn_pred = bagging_knn.predict(X_test)\n",
    "    bag_knn_proba = bagging_knn.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"Bagging + KNN Accuracy:\", accuracy_score(y_test, bag_knn_pred))\n",
    "    print(\"Bagging + KNN ROC-AUC:\", roc_auc_score(y_test, bag_knn_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc2396e-1bb6-4fc8-9c99-9917eed03fdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bagging with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ed3aeae-96df-4132-a111-ad82956388cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training & Evaluating Base Logistic Regression: 100%|████████████████████████████████████| 1/1 [00:05<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Logistic Regression Accuracy: 0.9710051546391752\n",
      "Base Logistic Regression ROC-AUC: 0.9910986005790017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#base performance - Logistic Regression\n",
    "for _ in tqdm(range(1), desc=\"Training & Evaluating Base Logistic Regression\"):\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    logreg_pred = logreg_model.predict(X_test)\n",
    "    logreg_proba = logreg_model.predict_proba(X_test)[:, 1]\n",
    "    print(\"Base Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
    "    print(\"Base Logistic Regression ROC-AUC:\", roc_auc_score(y_test, logreg_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60569728-1147-4f16-a07e-f737540d1bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bagging with Logistic Regression as base: 100%|█████████████████████████████████████████| 1/1 [01:43<00:00, 103.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging + Logistic Regression Accuracy: 0.9697164948453608\n",
      "Bagging + Logistic Regression ROC-AUC: 0.9927274184338907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging with Logistic Regression as base\n",
    "bagging_logreg = BaggingClassifier(\n",
    "    estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "for _ in tqdm(range(1), desc=\"Bagging with Logistic Regression as base\"):\n",
    "    bagging_logreg.fit(X_train, y_train)\n",
    "    bag_logreg_pred = bagging_logreg.predict(X_test)\n",
    "    bag_logreg_proba = bagging_logreg.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"Bagging + Logistic Regression Accuracy:\", accuracy_score(y_test, bag_logreg_pred))\n",
    "    print(\"Bagging + Logistic Regression ROC-AUC:\", roc_auc_score(y_test, bag_logreg_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c886d6-82b4-41af-b83c-df3b75a714b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bagging with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e51b053c-9499-41bb-bdd4-bb705bb9ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GridSearch for Base Decision Tree:   0%|                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GridSearch for Base Decision Tree: 100%|█████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params (Base Decision Tree): {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Base Decision Tree Accuracy: 0.9052835051546392\n",
      "Base Decision Tree ROC-AUC: 0.9461237941639036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#base: DecisionTreeClassifier w/ Gridsearch\n",
    "dt_param_grid = {\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"GridSearch for Base Decision Tree\"):\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred = best_dt.predict(X_test)\n",
    "dt_proba = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params (Base Decision Tree):\", dt_grid.best_params_)\n",
    "print(\"Base Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "print(\"Base Decision Tree ROC-AUC:\", roc_auc_score(y_test, dt_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719649c-21c6-4b53-a3e0-c319e8b254d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging with Decision Tree\n",
    "bagging_param_grid = {\n",
    "    \"n_estimators\": [100, 300, 600],#number of trees\n",
    "    \"max_samples\": [0.7],#fraction of training data\n",
    "    \"estimator__max_depth\": [None, 5, 10],#tune tree depth\n",
    "    \"estimator__min_samples_split\": [2],#tune split rules\n",
    "}\n",
    "\n",
    "bagging_dt = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bagging_grid = GridSearchCV(\n",
    "    bagging_dt,\n",
    "    bagging_param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"GridSearch for Bagging with Decision Tree\"):\n",
    "    bagging_grid.fit(X_train, y_train)\n",
    "\n",
    "best_bagging_dt = bagging_grid.best_estimator_\n",
    "bag_dt_pred = best_bagging_dt.predict(X_test)\n",
    "bag_dt_proba = best_bagging_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params (Bagging + Decision Tree):\", bagging_grid.best_params_)\n",
    "print(\"Bagging + Decision Tree Accuracy:\", accuracy_score(y_test, bag_dt_pred))\n",
    "print(\"Bagging + Decision Tree ROC-AUC:\", roc_auc_score(y_test, bag_dt_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416602d2-14af-4eae-abf3-c38b4cf8ecf0",
   "metadata": {},
   "source": [
    "### **Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c65c94-72e1-47eb-8b0c-2b3dba3aebba",
   "metadata": {},
   "source": [
    "As seen from the accuracy scores above, bagging yields slightly worse results when using KNN and Logistic Regression as base models. This may be because bagging just reduces variance to improve stability and consequently, improve the results. That's helpful for models that are unstable, such as decision trees, but is actually not helpful for those that are already stable and have low variance, such as KNN and Logistic Regression. As a result, bagging multiple models of these on bootstrapped samples doesn't add much, and may even hurt performance slightly. Bagging also doesn't reduce bias, only variance, so it's not helpful in Logister Regression either.\n",
    "\n",
    "Furthermore, bootstrap sampling reduces the effective traning size. KNN and Logistic Regression benefit more from utilizing the full dataset, so that hurts their performance too.\n",
    "\n",
    "As seen from the results of using bagging on decision tree classifiers, it greatly improves performance in terms of accuracy and ROC-AUC, meaning that it can differentiate and classify properly at an accurate level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e905dc7-336f-4dbd-9534-70ecdc85fbce",
   "metadata": {},
   "source": [
    "3. Using your own dataset, perform boosting (AdaBoost, XGBoost, and etc) and stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ba913-bf72-4f1d-8945-2d405dadcb50",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0200c-4ac8-473a-b918-4eea4c7bb98e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede509a-3b31-4ec2-a522-2eccdf49f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base: DecisionTreeClassifier w/ Gridsearch\n",
    "dt_param_grid = {\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"GridSearch for Base Decision Tree\"):\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred = best_dt.predict(X_test)\n",
    "dt_proba = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params (Base Decision Tree):\", dt_grid.best_params_)\n",
    "print(\"Base Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "print(\"Base Decision Tree ROC-AUC:\", roc_auc_score(y_test, dt_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c37355-d011-4004-8486-2e1a22cafac1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6805c-b7cb-4d70-921a-2f7ab06f1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "ada_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 1.0],\n",
    "    \"estimator__max_depth\": [1, 2]#depth of decision stump/tree\n",
    "}\n",
    "\n",
    "adaboost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search_ada = GridSearchCV(\n",
    "    adaboost,\n",
    "    ada_param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"GridSearch for AdaBoost\"):\n",
    "    grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "best_adaboost = grid_search_ada.best_estimator_\n",
    "ada_pred = best_adaboost.predict(X_test)\n",
    "ada_proba = best_adaboost.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params (AdaBoost):\", grid_search_ada.best_params_)\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, ada_pred))\n",
    "print(\"AdaBoost ROC-AUC:\", roc_auc_score(y_test, ada_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e0384-3f51-4e0e-a42d-ffb8a84b0dbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c8229-50ef-48f2-8767-05a934393431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    xgb,\n",
    "    xgb_param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"GridSearch for XGBoost\"):\n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "xgb_pred = best_xgb.predict(X_test)\n",
    "xgb_proba = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params (XGBoost):\", grid_search_xgb.best_params_)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_pred))\n",
    "print(\"XGBoost ROC-AUC:\", roc_auc_score(y_test, xgb_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e85193-2367-432e-a9c6-1d66f08c5108",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51801d8-1d4e-4682-8935-e508e697e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "cat_param_grid = {\n",
    "    \"iterations\": [200, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"depth\": [4, 6, 8],\n",
    "    \"l2_leaf_reg\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "catboost = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search_cat = GridSearchCV(\n",
    "    catboost,\n",
    "    cat_param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"GridSearch for CatBoost\"):\n",
    "    grid_search_cat.fit(X_train, y_train)\n",
    "\n",
    "best_cat = grid_search_cat.best_estimator_\n",
    "cat_pred = best_cat.predict(X_test)\n",
    "cat_proba = best_cat.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params (CatBoost):\", grid_search_cat.best_params_)\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, cat_pred))\n",
    "print(\"CatBoost ROC-AUC:\", roc_auc_score(y_test, cat_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b278ce-add8-433c-81c9-b734853d1b61",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ad78a-254b-4564-ab55-0cd9aab05190",
   "metadata": {},
   "source": [
    "I used logistic regression, KNN, and SVM, then stacked RandomForest on top of it as the final estimator. Then, I ran GridSearch on the final estimator (which is Random Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ff555-9ec9-4a3e-93ac-ce421659d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=11)),\n",
    "        ('svc', SVC(probability=True, random_state=42))\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(random_state=43),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#GridSearch for final estimator\n",
    "param_grid = {\n",
    "    \"final_estimator__n_estimators\": [50, 100, 200, 300],\n",
    "    \"final_estimator__max_depth\": [None, 5, 10, 20],\n",
    "    \"final_estimator__min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"Tuning Meta-Learner with GridSearch\"):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=stacking_clf,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Params for Meta-Learner (RF):\", grid_search.best_params_)\n",
    "    print(\"Best ROC-AUC Score (CV):\", grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Stacking Test Accuracy:\", accuracy_score(y_test, test_pred))\n",
    "    print(\"Stacking Test ROC-AUC:\", roc_auc_score(y_test, test_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a019b3-f63b-4eb8-9a26-3a364a724225",
   "metadata": {},
   "source": [
    "4. For stacking, identify the different models you used and their performances vs their performance when stacked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1b0e6-7258-4030-bb1f-e3c0735d6ff1",
   "metadata": {},
   "source": [
    "#### Logistic Regression Only vs when stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa9af4-62a8-4f18-b9b4-078044dca8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"Training & Evaluating Base Logistic Regression\"):\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    logreg_pred = logreg_model.predict(X_test)\n",
    "    logreg_proba = logreg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    base_acc = accuracy_score(y_test, logreg_pred)\n",
    "    base_auc = roc_auc_score(y_test, logreg_proba)\n",
    "\n",
    "    print(\"Base Logistic Regression Accuracy:\", base_acc)\n",
    "    print(\"Base Logistic Regression ROC-AUC:\", base_auc)\n",
    "\n",
    "#Compare with stacking model\n",
    "stack_pred = best_model.predict(X_test)#best_model is from GridSearch\n",
    "stack_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "stack_acc = accuracy_score(y_test, stack_pred)\n",
    "stack_auc = roc_auc_score(y_test, stack_proba)\n",
    "\n",
    "print(\"Comparison\")\n",
    "print(f\"Logistic Regression Accuracy: {base_acc:.4f} | Stacking Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"Logistic Regression ROC-AUC:  {base_auc:.4f} | Stacking ROC-AUC:  {stack_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd30fec-e701-4d8c-96d4-c0776f98a1e5",
   "metadata": {},
   "source": [
    "#### KNN Only vs when stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70985f3b-4d99-4549-b8ce-f176af114c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"Training & Evaluating Base KNN\"):\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    knn_pred = knn_model.predict(X_test)\n",
    "    knn_proba = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    base_acc = accuracy_score(y_test, knn_pred)\n",
    "    base_auc = roc_auc_score(y_test, knn_proba)\n",
    "\n",
    "    print(\"Base KNN Accuracy:\", base_acc)\n",
    "    print(\"Base KNN ROC-AUC:\", base_auc)\n",
    "\n",
    "#Compare with Stacking Model\n",
    "stack_pred = best_model.predict(X_test)#best_model is from GridSearch\n",
    "stack_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "stack_acc = accuracy_score(y_test, stack_pred)\n",
    "stack_auc = roc_auc_score(y_test, stack_proba)\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(f\"KNN Accuracy: {base_acc:.4f} | Stacking Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"KNN ROC-AUC:  {base_auc:.4f} | Stacking ROC-AUC:  {stack_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8fc26-d8a5-4782-a697-a8d6db649d15",
   "metadata": {},
   "source": [
    "#### SVM Only vs when stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df915ec8-8f33-482f-80d4-15d675aaaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"Training & Evaluating Base SVM\"):\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_pred = svm_model.predict(X_test)\n",
    "    svm_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    base_acc = accuracy_score(y_test, svm_pred)\n",
    "    base_auc = roc_auc_score(y_test, svm_proba)\n",
    "\n",
    "    print(\"Base SVM Accuracy:\", base_acc)\n",
    "    print(\"Base SVM ROC-AUC:\", base_auc)\n",
    "\n",
    "\n",
    "#Compare with stacking Model\n",
    "stack_pred = best_model.predict(X_test)#best_model is from GridSearch\n",
    "stack_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "stack_acc = accuracy_score(y_test, stack_pred)\n",
    "stack_auc = roc_auc_score(y_test, stack_proba)\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(f\"SVM Accuracy: {base_acc:.4f} | Stacking Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"SVM ROC-AUC:  {base_auc:.4f} | Stacking ROC-AUC:  {stack_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28917b8-9605-4ed1-8b5c-76242129fae8",
   "metadata": {},
   "source": [
    "5. Evaluate the different ensemble learning methods used in this activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3a138-7d6c-4d44-961b-0be189f3ea80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc9820-d80b-4f69-92f4-c3441ad5c68c",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c482f3-5e45-4205-808e-b2ec8677ffff",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c4cf3-ba48-4ce4-b7be-052384fbb3db",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158e6b4-4f61-4707-acde-08493649605a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3407551-2f6e-4320-95b6-3146ee57f12f",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960348b-96af-405d-b762-b20b25f58d0f",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa96c7-6f2d-48ff-968a-335592e6712c",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c1b7c-a0f1-49b3-9b34-123cf4e5b025",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651110fd-224e-4387-bb22-5395b8270ab3",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9cf514-23e3-4f23-ade8-1741599a4b65",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8e1b0-d7a8-439d-8746-2fd40e82dd0f",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302c833-656a-486a-91ca-209346487681",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb384d-b9fd-4946-974d-1f2f9cd8df5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CPE312_Pascual]",
   "language": "python",
   "name": "conda-env-CPE312_Pascual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
